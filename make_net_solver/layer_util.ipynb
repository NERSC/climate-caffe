{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "\n",
    "from caffe import layers as L, params as P, to_proto\n",
    "\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "from caffe.coord_map import crop\n",
    "\n",
    "import copy\n",
    "from os.path import join\n",
    "\n",
    "def conv_relu(bottom, ks, nout, stride=1, pad=0, group=1, no_relu=False):\n",
    "    conv = L.Convolution(bottom, \n",
    "                         kernel_size=ks, \n",
    "                         stride=stride,\n",
    "                         num_output=nout, \n",
    "                         pad=pad, \n",
    "                         group=group, \n",
    "                         weight_filler={\"type\":\"msra\"})\n",
    "    if not no_relu:\n",
    "        conv = L.ReLU(conv, in_place=True)\n",
    "    return conv\n",
    "\n",
    "def fc_relu(bottom, nout):\n",
    "    fc = L.InnerProduct(bottom, num_output=nout)\n",
    "    return fc, L.ReLU(fc, in_place=True)\n",
    "\n",
    "def max_pool(bottom, ks=2, stride=2):\n",
    "    return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)\n",
    "\n",
    "def deconv_relu(bottom, ks, nout, stride=1, pad=0, group=1, crop=0, no_relu=False):\n",
    "    convolution_param = dict(kernel_size=ks, \n",
    "                         stride=stride,\n",
    "                         num_output=nout, \n",
    "                         pad=pad, \n",
    "                         group=group, \n",
    "                         weight_filler={\"type\":\"msra\"})\n",
    "    deconv = L.Deconvolution(bottom,convolution_param=convolution_param)\n",
    "    if no_relu:\n",
    "        return deconv\n",
    "    else:\n",
    "        return L.ReLU(deconv, in_place=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def get_blob_shape(blob):\n",
    "    _,fn = write_to_file(blob,filename=\"tmp\")\n",
    "    net = caffe.Net(fn, caffe.TEST)\n",
    "    blob_key = net.blobs.keys()[-1]\n",
    "    blob_obj = net.blobs[blob_key]\n",
    "    blob_shape = [blob_obj.shape[i] for i in range(len(blob_obj.shape))]\n",
    "    return blob_shape\n",
    "    \n",
    "    \n",
    "def convert_layer_to_prototxt(netspec):\n",
    "    return str(netspec.to_proto())\n",
    "\n",
    "\n",
    "\n",
    "def write_to_file(netspecs,filename=\"train.prototxt\", basepath=\".\"):\n",
    "    \n",
    "    \n",
    "    filepath = join(basepath, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        for netspec in netspecs:\n",
    "            prototxt_str = convert_layer_to_prototxt(netspec)\n",
    "            f.write(prototxt_str)\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "\n",
    "#add engine caffe\n",
    "def add_engine_caffe(pstr, fn):\n",
    "    splits = pstr.split(\"operation: SUM\")\n",
    "    newstr=''.join(splits[:-1] + [\"operation: SUM\\n    engine: CAFFE\"] +[splits[-1]])\n",
    "    write_prototxt_str(fn, newstr)\n",
    "    return newstr\n",
    "\n",
    "def get_dummy_shape(data):\n",
    "    return data.fn.params[\"shape\"][\"dim\"]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
