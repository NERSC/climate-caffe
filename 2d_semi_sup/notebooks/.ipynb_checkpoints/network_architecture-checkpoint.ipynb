{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from layer_util.ipynb\n"
     ]
    }
   ],
   "source": [
    "import caffe\n",
    "\n",
    "from caffe import layers as L, params as P, to_proto\n",
    "\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "from caffe.coord_map import crop\n",
    "\n",
    "import copy\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from layer_util import *\n",
    "    \n",
    "\n",
    "CAFFE=1\n",
    "SUM=1\n",
    "PROD = 0\n",
    "MAX = 2\n",
    "\n",
    "def encode(n, conv, nfilters_list, num_layers, type_=\"labelled\"):\n",
    "    encoder_blobs = [conv]\n",
    "    for i in range(num_layers):\n",
    "        nfilters = nfilters_list[i]\n",
    "        conv = conv_relu(conv, ks=5, nout=nfilters, pad=2, stride=2)\n",
    "        encoder_blobs.append(conv)\n",
    "\n",
    "    n.encoder = conv\n",
    "    return n, encoder_blobs\n",
    "    \n",
    "def decode(n, encoder, encoder_blobs, nfilters_list, num_layers, num_input_channels):\n",
    "    #remove last layer and correpsonding number of filters b/c we don't use the last number in reverse\n",
    "    nfilters_list.pop()\n",
    "    encoder_blobs.pop()\n",
    "    \n",
    "    #reverse the list b/c decoding goes in reverse\n",
    "    nfilters_list.reverse()\n",
    "    encoder_blobs.reverse()\n",
    "    \n",
    "    # add the channel size of input data for full reconstruction\n",
    "    nfilters_list.append(num_input_channels)\n",
    "\n",
    "    conv = encoder\n",
    "    for i in range(num_layers):\n",
    "        nfilters = nfilters_list[i]\n",
    "        conv = deconv_relu(conv,5, nfilters, stride=2)\n",
    "        conv = L.Crop(conv, encoder_blobs[i], axis=2,offset=1)\n",
    "    n.reconstruction = conv\n",
    "    return n\n",
    "\n",
    "def bbox_reg(n, num_classes):\n",
    "    n.gxy, n.gwh, n.gobj, n.gcls = L.Slice(n.label, slice_point=[2,4,5], ntop=4)\n",
    "    \n",
    "\n",
    "    n.class_scores = conv_relu(n.encoder,ks=3,pad=1,nout=num_classes)\n",
    "\n",
    "    \n",
    "    n.obj_scores = conv_relu(n.encoder,ks=3,pad=1,nout=2)\n",
    "\n",
    "    n = get_coord_scores(n)\n",
    "    \n",
    "\n",
    "    return n\n",
    "    \n",
    "def get_coord_scores(n):\n",
    "    # no relu here so we can get negative numbers because inverse log of - negative -> gives us boxes\n",
    "    # of size smaller than 64x64\n",
    "    n.xy_param = conv_relu(n.encoder,ks=3,pad=1,nout=2, no_relu=True)\n",
    "    n.wh_param = conv_relu(n.encoder,ks=3,pad=1,nout=2, no_relu=True)\n",
    "    \n",
    "    n.two_d_mask = L.Concat(*2*[n.gobj])\n",
    "    n.xy_pred = L.Eltwise(n.xy_param,n.two_d_mask, operation=PROD)\n",
    "    n.wh_pred = L.Eltwise(n.wh_param,n.two_d_mask, operation=PROD)\n",
    "    n.xy_gt = L.Eltwise(n.gxy,n.two_d_mask, operation=PROD)\n",
    "    n.wh_gt = L.Eltwise(n.gwh,n.two_d_mask, operation=PROD)\n",
    "    return n\n",
    "\n",
    "    \n",
    "def create_net(n, data ,nfilters_list, num_classes, num_input_channels):\n",
    "\n",
    "    num_layers = len(nfilters_list)\n",
    "    n, encoder_blobs = encode(n, data, nfilters_list, num_layers)\n",
    "\n",
    "    \n",
    "    n = decode(n, n.encoder, encoder_blobs, nfilters_list, num_layers, num_input_channels)\n",
    "    \n",
    "    n=bbox_reg(n, num_classes)\n",
    "\n",
    "    return n\n",
    "\n",
    "\n",
    "def make_loss(n):\n",
    "    alpha = 5.\n",
    "    beta = 7.\n",
    "    gamma = 0.5\n",
    "    lambda_ = 0.1\n",
    "    \n",
    "    n.L_cls = L.SoftmaxWithLoss(n.class_scores, n.gcls, loss_param =dict(ignore_label=0))\n",
    "    n.L_obj = L.SoftmaxWithLoss(n.obj_scores, n.gobj, loss_param =dict(ignore_label=0))\n",
    "    n.L_xy = L.SmoothL1Loss(n.xy_pred, n.xy_gt)\n",
    "    n.L_wh = L.SmoothL1Loss(n.wh_pred, n.wh_gt)\n",
    "    \n",
    "    n.L_rec = L.EuclideanLoss(n.reconstruction, n.data)\n",
    "    n.final_loss = L.Eltwise(n.L_cls, n.L_obj, n.L_xy, n.L_wh,n.L_rec, coeff=[1.,1.,alpha, beta,10**-5], operation=SUM)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
