{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "\n",
    "from caffe import layers as L, params as P, to_proto\n",
    "\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "from caffe.coord_map import crop\n",
    "\n",
    "import copy\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from layer_util import *\n",
    "    \n",
    "\n",
    "CAFFE=1\n",
    "SUM=1\n",
    "PROD = 0\n",
    "MAX = 2\n",
    "def encode(n, conv, nfilters_list, num_layers):\n",
    "    encoder_blobs = [conv]\n",
    "    for i in range(num_layers):\n",
    "        nfilters = nfilters_list[i]\n",
    "        conv = conv_relu(conv, ks=5, nout=nfilters, pad=2, stride=2)\n",
    "        encoder_blobs.append(conv)\n",
    "    n.encoder = conv\n",
    "    return n, encoder_blobs\n",
    "    \n",
    "def decode(n, encoder, encoder_blobs, nfilters_list, num_layers, num_input_channels):\n",
    "    #remove last layer and correpsonding number of filters b/c we don't use the last number in reverse\n",
    "    nfilters_list.pop()\n",
    "    encoder_blobs.pop()\n",
    "    \n",
    "    #reverse the list b/c decoding goes in reverse\n",
    "    nfilters_list.reverse()\n",
    "    encoder_blobs.reverse()\n",
    "    \n",
    "    # add the channel size of input data for full reconstruction\n",
    "    nfilters_list.append(num_input_channels)\n",
    "\n",
    "    conv = encoder\n",
    "    for i in range(num_layers):\n",
    "        nfilters = nfilters_list[i]\n",
    "        conv = deconv_relu(conv,5, nfilters, stride=2)\n",
    "        conv = L.Crop(conv, encoder_blobs[i], axis=2,offset=1)\n",
    "    n.decoder = conv\n",
    "    return n\n",
    "\n",
    "def bbox_reg(n, num_classes):\n",
    "    n.gxywh, n.gobj, n.gcls = L.Slice(n.label, slice_point=[4,5], ntop=3)\n",
    "    \n",
    "    #n.gx, n.gy = L.Slice(n.gxy, slice_point=[1], ntop=2)\n",
    "\n",
    "    n.class_scores = conv_relu(n.encoder,ks=3,pad=1,nout=num_classes)\n",
    "\n",
    "    \n",
    "    n.obj_scores = conv_relu(n.encoder,ks=3,pad=1,nout=2)\n",
    "\n",
    "    \n",
    "    \n",
    "    n.xywh_param = conv_relu(n.encoder,ks=3,pad=1,nout=4, no_relu=True)\n",
    "    n.four_d_mask = L.Concat(*4*[n.gobj])\n",
    "    n.mask_pred = L.Eltwise(n.xywh_param,n.four_d_mask, operation=PROD)\n",
    "    n.mask_xywh = L.Eltwise(n.gxywh,n.four_d_mask, operation=PROD)\n",
    "    return n\n",
    "    \n",
    "    \n",
    "def create_net(n, data,nfilters_list, num_classes, num_input_channels):\n",
    "\n",
    "    num_layers = len(nfilters_list)\n",
    "    conv = data\n",
    "    n, encoder_blobs = encode(n, conv, nfilters_list, num_layers)\n",
    "    \n",
    "    n = decode(n, n.encoder, encoder_blobs, nfilters_list, num_layers, num_input_channels)\n",
    "   \n",
    "\n",
    "    rec = n.decoder\n",
    "    \n",
    "    n=bbox_reg(n, num_classes)\n",
    "\n",
    "    return n\n",
    "\n",
    "\n",
    "def make_loss(n):\n",
    "    n.L_cls = L.SoftmaxWithLoss(n.class_scores, n.gcls, loss_param =dict(ignore_label=0))\n",
    "    n.L_obj = L.SoftmaxWithLoss(n.obj_scores, n.gobj, loss_param =dict(ignore_label=0))\n",
    "    n.L_coord = L.EuclideanLoss(n.mask_pred, n.mask_xywh) # TODO: switch to SmoothL1\n",
    "    n.final_loss = L.Eltwise(n.L_cls, n.L_obj,n.L_coord, operation=SUM)\n",
    "    return n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
