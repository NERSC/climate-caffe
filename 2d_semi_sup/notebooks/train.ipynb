{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def do_train(solver, cl_args):\n",
    "    tr_its_per_epoch = int(float(num_tr) / tr_batch_size)\n",
    "    #val_its_per_epoch = int(float(num_val) / val_batch_size)\n",
    "    num_epochs = cl_args[\"num_epochs\"]\n",
    "\n",
    "    loss_keys = [\"L_cls\",\"L_obj\",\"L_xy\",\"L_wh\",\"L_rec\",\"final_loss\"]\n",
    "    losses = {}\n",
    "    for ep in range(num_epochs):\n",
    "        losses[ep] = {k:[] for k in loss_keys}\n",
    "        losses[str(ep) + \"_mean\"] = {k:0 for k in loss_keys}\n",
    "        for it in range(tr_its_per_epoch):\n",
    "            solver.step(1)\n",
    "\n",
    "            for k in loss_keys:\n",
    "                loss = np.float32(solver.net.blobs[k].data)\n",
    "                losses[ep][k].append(loss)\n",
    "\n",
    "        losses[str(ep) + \"_mean\"] = {k:np.mean(losses[ep][k]) for k in loss_keys}\n",
    "        for k in loss_keys:\n",
    "            loss = losses[str(ep) + \"_mean\"][k]\n",
    "            sys.stderr.write(\"\\n Epoch %i: Final %s Loss = %6.3f\\n\" % (ep, k, loss))\n",
    "        suffix = \"learning_curve_lr_%8.6f_fs_%4.3f_%s.jpg\"%(cl_args[\"lr\"], cl_args[\"filters_scale\"], cl_args[\"data_dir\"])\n",
    "        plt.figure(1)\n",
    "        plt.plot([losses[str(epoch) + \"_mean\"][\"final_loss\"] for epoch in range(ep + 1)])\n",
    "        #plt.show()\n",
    "        plt.savefig(join(cl_args[\"save_dir\"],\"tr_\" + suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    def get_cl_args():\n",
    "        cl_args = {\"lr\": 0.00001,\n",
    "                   \"num_epochs\": 20, \n",
    "                   \"filters_scale\": 1./8,\n",
    "                   \"data_dir\": \"extremely_small_dataset\", \n",
    "                   \"save_dir\": \"/global/homes/r/racah/projects/climate-caffe/2d_semi_sup/notebooks/plots\",\n",
    "                   \"tr_batch_size\":4,\n",
    "                   \"val_batch_size\":16 }\n",
    "\n",
    "        if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "            sys.argv=sys.argv[:1]\n",
    "\n",
    "        parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "        for k,v in cl_args.iteritems():\n",
    "            parser.add_argument('--' + k, type=type(v), default=v, help=k)\n",
    "\n",
    "        args = parser.parse_args()\n",
    "        cl_args.update(args.__dict__)\n",
    "        return cl_args\n",
    "    \n",
    "    \n",
    "    #get solver\n",
    "    solver_filename = ...\n",
    "    num_tr = ...\n",
    "    solver = caffe.SGDSolver(solver_filename)\n",
    "    do_train(solver, cl_args)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
