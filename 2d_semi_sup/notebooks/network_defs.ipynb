{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from layer_util.ipynb\n",
      "importing Jupyter notebook from network_architecture.ipynb\n"
     ]
    }
   ],
   "source": [
    "import caffe\n",
    "\n",
    "from caffe import layers as L, params as P, to_proto\n",
    "\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "from caffe.coord_map import crop\n",
    "\n",
    "import copy\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from layer_util import *\n",
    "from network_architecture import *\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net_vars = [\"PRECT\",\n",
    "\"PS\",\n",
    "\"PSL\",\n",
    "\"QREFHT\",\n",
    "\"T200\",\n",
    "\"T500\",\n",
    "\"TMQ\",\n",
    "\"TREFHT\",\n",
    "\"TS\",\n",
    "\"U850\",\n",
    "\"UBOT\",\n",
    "\"V850\",\n",
    "\"VBOT\",\n",
    "\"Z1000\",\n",
    "\"Z200\",\n",
    "\"ZBOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lbl_vars = [ \"x_coord\",\n",
    "            \"y_coord\",\n",
    "            \"w_coord\",\n",
    "            \"h_coord\",\n",
    "            \"obj\",\n",
    "            \"cls\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_netcdf_network(inp_x = 768,inp_y=768,\n",
    "                        num_classes=4, \n",
    "                        name=\"netcdf\",\n",
    "                        batch_size=16, \n",
    "                        prefix_path=\"/project/projectdirs/dasrepo/gordon_bell/deep_learning/networks/climate/2d_semi_sup\",\n",
    "                        prefix_dir=\"smaller_dataset\", \n",
    "                        mode=\"tr\", \n",
    "                        filters_scale=1./8,\n",
    "                       dummy_data=False):\n",
    "    \n",
    "    \n",
    "    prefix = join(prefix_path, prefix_dir)\n",
    "    num_channels = len(net_vars)\n",
    "\n",
    "    time_stride =1\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    if dummy_data:\n",
    "        n.data = L.DummyData(shape={'dim':[batch_size,num_channels,inp_x,inp_y]}, \n",
    "                             data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "        n.label = L.DummyData(shape={'dim':[batch_size,6,24,24]}, \n",
    "                             data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    else:    \n",
    "        n.data = L.NetCDFData(source=join(prefix,mode+\"_image_files.txt\"),\n",
    "                           variable_data=net_vars, time_stride=time_stride,crop_stride=32,\n",
    "                            batch_size=batch_size, name=\"labelled_data\",xdim=768, ydim=768, \n",
    "                              crop_index_source=join(prefix,mode+\"_crop_indices.txt\"))\n",
    "\n",
    "\n",
    "        n.label = L.NetCDFData(source=join(prefix,mode+\"_label_files.txt\"),\n",
    "                           variable_data=lbl_vars, time_stride=time_stride,\n",
    "                            batch_size=batch_size, name=\"labelled_data\",xdim=24, ydim=24,\n",
    "                              crop_index_source=join(prefix,mode+\"_crop_indices.txt\"))\n",
    "    \n",
    "    n.normalized_data = L.MVN(n.data)\n",
    "    nfilters_list = [128, 256, 512, 768, 1024]\n",
    "    nfilters_list = [int(f * filters_scale) for f in nfilters_list]\n",
    "    print nfilters_list\n",
    "    \n",
    "    num_examples = get_num_examples(join(prefix,mode+\"_image_files.txt\"), time_stride=time_stride)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n = create_net(n,nfilters_list, num_classes, num_channels)\n",
    "    n = make_loss(n)\n",
    "    pstr = convert_layer_to_prototxt(n)\n",
    "\n",
    "    return pstr, n, num_examples\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_examples(txt_file, time_stride=1, examples_per_file=8):\n",
    "    with open(txt_file, 'r') as f:\n",
    "        num_examples = len(f.readlines()) * (examples_per_file / time_stride)\n",
    "    return num_examples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dummy_network(inp_x = 768,inp_y=1152,lbl_ch = (4,4,2),batch_size=2, num_layers=6, name=\"sm_sq_2d\"):\n",
    "    nfilters_list = [128, 256, 512, 768, 1024, 1280]\n",
    "    n = caffe.NetSpec()\n",
    "    n.data = L.DummyData(shape={'dim':[batch_size,16,inp_x,inp_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    lbl_x = inp_x / 64\n",
    "    lbl_y = inp_y / 64\n",
    "    n.label1 = L.DummyData(shape={'dim':[batch_size,lbl_ch[0],lbl_x, lbl_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    n.label2 = L.DummyData(shape={'dim':[batch_size,lbl_ch[1],lbl_x, lbl_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    n.label3 = L.DummyData(shape={'dim':[batch_size,lbl_ch[2],lbl_x, lbl_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    n.label = L.Concat(n.label1, n.label2, n.label3)\n",
    "    n = create_net(n,n.data,nfilters_list, lbl_ch, num_chanels=16)\n",
    "    n = make_loss(n)\n",
    "\n",
    "\n",
    "\n",
    "    pstr, fn = write_to_file(n, name)\n",
    "    return pstr, fn, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n = caffe.NetSpec()\n",
    "# n.data = L.NetCDFData(source=\"/global/homes/r/racah/projects/climate-caffe/2d_semi_sup/source_files.txt\",\n",
    "#                        variable_data=net_vars, time_stride=2,\n",
    "#                         batch_size=4, name=\"foo\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
