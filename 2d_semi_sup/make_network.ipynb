{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "\n",
    "from caffe import layers as L, params as P, to_proto\n",
    "\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "from caffe.coord_map import crop\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(bottom, ks, nout, stride=1, pad=0, group=1):\n",
    "    conv = L.Convolution(bottom, kernel_size=ks, stride=stride,\n",
    "                                num_output=nout, pad=pad, group=group, weight_filler={\"type\":\"msra\"})\n",
    "    return L.ReLU(conv, in_place=True)\n",
    "\n",
    "def fc_relu(bottom, nout):\n",
    "    fc = L.InnerProduct(bottom, num_output=nout)\n",
    "    return fc, L.ReLU(fc, in_place=True)\n",
    "\n",
    "def max_pool(bottom, ks=2, stride=2):\n",
    "    return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)\n",
    "\n",
    "def deconv_relu(bottom, ks, nout, stride=1, pad=0, group=1, crop=0):\n",
    "    convolution_param = dict(num_output=nout, kernel_size=ks, stride=stride,pad=pad, group=group,\n",
    "            bias_term=False)\n",
    "    deconv = L.Deconvolution(bottom,convolution_param=convolution_param)\n",
    "    return L.ReLU(deconv, in_place=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def get_blob_shape(blob):\n",
    "    _,fn = write_to_file(blob,filename=\"tmp\")\n",
    "    net = caffe.Net(fn, caffe.TEST)\n",
    "    blob_key = net.blobs.keys()[-1]\n",
    "    blob_obj = net.blobs[blob_key]\n",
    "    blob_shape = [blob_obj.shape[i] for i in range(len(blob_obj.shape))]\n",
    "    return blob_shape\n",
    "    \n",
    "    \n",
    "def convert_layer_to_prototxt(layer):\n",
    "    return str(to_proto(layer))\n",
    "\n",
    "def write_prototxt_str(filename, prototxt_str):\n",
    "    #print prototxt_str\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(prototxt_str)\n",
    "\n",
    "def write_to_file(layer,filename=\"train\"):\n",
    "    \n",
    "    prototxt_str = convert_layer_to_prototxt(layer)\n",
    "\n",
    "    write_prototxt_str(filename + \".prototxt\", prototxt_str)\n",
    "    \n",
    "    return prototxt_str, filename + \".prototxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_vars = [\"PRECT\",\n",
    "\"PS\",\n",
    "\"PSL\",\n",
    "\"QREFHT\",\n",
    "\"T200\",\n",
    "\"T500\",\n",
    "\"TMQ\",\n",
    "\"TREFHT\",\n",
    "\"TS\",\n",
    "\"U850\",\n",
    "\"UBOT\",\n",
    "\"V850\",\n",
    "\"VBOT\",\n",
    "\"Z1000\",\n",
    "\"Z200\",\n",
    "\"ZBOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "CAFFE=1\n",
    "SUM=1\n",
    "\n",
    "def make_netcdf_network(inp_x = 768,inp_y=1152,lbl_ch = (4,4,2), name=\"netcdf\"):\n",
    "    data = L.NetCDFData(source=,\n",
    "                       variable_data=net_vars, variable_label=[\"xmin\"], batch_size=2)\n",
    "    conv = conv_relu(data, ks=5, nout=8, pad=2, stride=2)\n",
    "    pstr, fn = write_to_file(conv, name)\n",
    "    return pstr, fn, conv\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def make_network(inp_x = 768,inp_y=1152,lbl_ch = (4,4,2), name=\"sm_sq_2d\"):\n",
    "    data = L.DummyData(shape={'dim':[batch_size,16,inp_x,inp_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    lbl_x = inp_x / 64\n",
    "    lbl_y = inp_y / 64\n",
    "    label1 = L.DummyData(shape={'dim':[batch_size,lbl_ch[0],lbl_x, lbl_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    label2 = L.DummyData(shape={'dim':[batch_size,lbl_ch[1],lbl_x, lbl_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    label3 = L.DummyData(shape={'dim':[batch_size,lbl_ch[2],lbl_x, lbl_y]}, data_filler={\"type\":\"gaussian\", \"mean\":0, \"std\":1})\n",
    "    nfilters_list = [128, 256, 512, 768, 1024, 1280]\n",
    "    #nfilters_list = [f/2 for f in nfilters_list ]\n",
    "    conv = data\n",
    "\n",
    "    num_layers = 6\n",
    "    encoder_blobs = [data]\n",
    "    for i in range(num_layers):\n",
    "        nfilters = nfilters_list[i]\n",
    "        conv = conv_relu(conv, ks=5, nout=nfilters, pad=2, stride=2)\n",
    "        encoder_blobs.append(conv)\n",
    "\n",
    "    nfilters_list.pop()\n",
    "    nfilters_list.reverse()\n",
    "    encoder_blobs.pop()\n",
    "    encoder_blobs.reverse()\n",
    "    nfilters_list.append(16)\n",
    "\n",
    "    encoder = conv\n",
    "    print get_blob_shape(encoder)\n",
    "    for i in range(num_layers):\n",
    "        nfilters = nfilters_list[i]\n",
    "        conv = deconv_relu(conv,5, nfilters, stride=2)\n",
    "        conv = L.Crop(conv,encoder_blobs[i], axis=2,offset=1)\n",
    "        #print get_blob_shape(conv)\n",
    "\n",
    "    rec = conv\n",
    "\n",
    "    conv1 = conv_relu(encoder,ks=3,pad=1,nout=lbl_ch[0])\n",
    "\n",
    "    conv2 = L.Convolution(encoder,kernel_size=3,pad=1, stride=1, num_output=lbl_ch[1])\n",
    "\n",
    "    conv2 = L.Sigmoid(conv2)\n",
    "    conv3 = L.Convolution(encoder,kernel_size=3,pad=1,stride=1, num_output=lbl_ch[2])\n",
    "\n",
    "    conv3 = L.Sigmoid(conv3)\n",
    "    yolo = L.Concat(conv1,conv2, conv3)\n",
    "    lbl = L.Concat(label1, label2, label3)\n",
    "    loss1 = L.EuclideanLoss(yolo, lbl)\n",
    "    lossr = L.EuclideanLoss(rec,data)\n",
    "    final_loss = L.Eltwise(loss1,lossr,operation=SUM)\n",
    "    pstr, fn = write_to_file(final_loss, name)\n",
    "    return pstr, fn, final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'TMQ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a6cd7fcdb6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmake_netcdf_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-144ca832d913>\u001b[0m in \u001b[0;36mmake_netcdf_network\u001b[0;34m(inp_x, inp_y, lbl_ch, name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_netcdf_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1152\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbl_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"netcdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     data = L.NetCDFData(source=                        \"/project/projectdirs/dasrepo/gordon_bell/deep_learning/data/climate/CAM5_0.25/climo/big_images/netcdf_files/cam5_1_amip_run2.cam2.h2.1979-01-01-00000.nc\",\n\u001b[0;32m----> 7\u001b[0;31m                        variable_data=[TMQ,VBOT], variable_label=[\"xmin\"], batch_size=2)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'TMQ' is not defined"
     ]
    }
   ],
   "source": [
    "pstr, fn, fl= make_netcdf_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1280, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "# name = \"sm_sq_2d_16\"\n",
    "# pstr, fn, fl = make_network(inp_x=768,inp_y=768,lbl_ch=(16,16,16), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "net=caffe.Net(fn,caffe.TRAIN)\n",
    "\n",
    "net.forward()\n",
    "\n",
    "net.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add engine caffe\n",
    "def add_engine_caffe(pstr, fn):\n",
    "    splits = pstr.split(\"operation: SUM\")\n",
    "    newstr=''.join(splits[:-1] + [\"operation: SUM\\n    engine: CAFFE\"] +[splits[-1]])\n",
    "    write_prototxt_str(fn, newstr)\n",
    "    return newstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newstr= add_engine_caffe(pstr, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\n",
      "  name: \"DummyData1\"\n",
      "  type: \"DummyData\"\n",
      "  top: \"DummyData1\"\n",
      "  dummy_data_param {\n",
      "    data_filler {\n",
      "      type: \"gaussian\"\n",
      "      mean: 0\n",
      "      std: 1\n",
      "    }\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 16\n",
      "      dim: 768\n",
      "      dim: 768\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"DummyData1\"\n",
      "  top: \"Convolution1\"\n",
      "  convolution_param {\n",
      "    num_output: 128\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"msra\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution1\"\n",
      "  top: \"Convolution1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution1\"\n",
      "  top: \"Convolution2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"msra\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution2\"\n",
      "  top: \"Convolution2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution2\"\n",
      "  top: \"Convolution3\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"msra\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution3\"\n",
      "  top: \"Convolution3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution3\"\n",
      "  top: \"Convolution4\"\n",
      "  convolution_param {\n",
      "    num_output: 768\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"msra\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution4\"\n",
      "  top: \"Convolution4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution4\"\n",
      "  top: \"Convolution5\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"msra\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution5\"\n",
      "  top: \"Convolution5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution6\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution5\"\n",
      "  top: \"Convolution6\"\n",
      "  convolution_param {\n",
      "    num_output: 1280\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"msra\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution6\"\n",
      "  top: \"Convolution6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution7\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution6\"\n",
      "  top: \"Convolution7\"\n",
      "  convolution_param {\n",
      "    num_output: 16\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"msra\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution7\"\n",
      "  top: \"Convolution7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution8\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution6\"\n",
      "  top: \"Convolution8\"\n",
      "  convolution_param {\n",
      "    num_output: 16\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Sigmoid1\"\n",
      "  type: \"Sigmoid\"\n",
      "  bottom: \"Convolution8\"\n",
      "  top: \"Sigmoid1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution9\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Convolution6\"\n",
      "  top: \"Convolution9\"\n",
      "  convolution_param {\n",
      "    num_output: 16\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Sigmoid2\"\n",
      "  type: \"Sigmoid\"\n",
      "  bottom: \"Convolution9\"\n",
      "  top: \"Sigmoid2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Concat1\"\n",
      "  type: \"Concat\"\n",
      "  bottom: \"Convolution7\"\n",
      "  bottom: \"Sigmoid1\"\n",
      "  bottom: \"Sigmoid2\"\n",
      "  top: \"Concat1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"DummyData2\"\n",
      "  type: \"DummyData\"\n",
      "  top: \"DummyData2\"\n",
      "  dummy_data_param {\n",
      "    data_filler {\n",
      "      type: \"gaussian\"\n",
      "      mean: 0\n",
      "      std: 1\n",
      "    }\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 16\n",
      "      dim: 12\n",
      "      dim: 12\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"DummyData3\"\n",
      "  type: \"DummyData\"\n",
      "  top: \"DummyData3\"\n",
      "  dummy_data_param {\n",
      "    data_filler {\n",
      "      type: \"gaussian\"\n",
      "      mean: 0\n",
      "      std: 1\n",
      "    }\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 16\n",
      "      dim: 12\n",
      "      dim: 12\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"DummyData4\"\n",
      "  type: \"DummyData\"\n",
      "  top: \"DummyData4\"\n",
      "  dummy_data_param {\n",
      "    data_filler {\n",
      "      type: \"gaussian\"\n",
      "      mean: 0\n",
      "      std: 1\n",
      "    }\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 16\n",
      "      dim: 12\n",
      "      dim: 12\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Concat2\"\n",
      "  type: \"Concat\"\n",
      "  bottom: \"DummyData2\"\n",
      "  bottom: \"DummyData3\"\n",
      "  bottom: \"DummyData4\"\n",
      "  top: \"Concat2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"EuclideanLoss1\"\n",
      "  type: \"EuclideanLoss\"\n",
      "  bottom: \"Concat1\"\n",
      "  bottom: \"Concat2\"\n",
      "  top: \"EuclideanLoss1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Deconvolution1\"\n",
      "  type: \"Deconvolution\"\n",
      "  bottom: \"Convolution6\"\n",
      "  top: \"Deconvolution1\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    bias_term: false\n",
      "    pad: 0\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU8\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Deconvolution1\"\n",
      "  top: \"Deconvolution1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Crop1\"\n",
      "  type: \"Crop\"\n",
      "  bottom: \"Deconvolution1\"\n",
      "  bottom: \"Convolution5\"\n",
      "  top: \"Crop1\"\n",
      "  crop_param {\n",
      "    axis: 2\n",
      "    offset: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Deconvolution2\"\n",
      "  type: \"Deconvolution\"\n",
      "  bottom: \"Crop1\"\n",
      "  top: \"Deconvolution2\"\n",
      "  convolution_param {\n",
      "    num_output: 768\n",
      "    bias_term: false\n",
      "    pad: 0\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU9\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Deconvolution2\"\n",
      "  top: \"Deconvolution2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Crop2\"\n",
      "  type: \"Crop\"\n",
      "  bottom: \"Deconvolution2\"\n",
      "  bottom: \"Convolution4\"\n",
      "  top: \"Crop2\"\n",
      "  crop_param {\n",
      "    axis: 2\n",
      "    offset: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Deconvolution3\"\n",
      "  type: \"Deconvolution\"\n",
      "  bottom: \"Crop2\"\n",
      "  top: \"Deconvolution3\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    bias_term: false\n",
      "    pad: 0\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU10\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Deconvolution3\"\n",
      "  top: \"Deconvolution3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Crop3\"\n",
      "  type: \"Crop\"\n",
      "  bottom: \"Deconvolution3\"\n",
      "  bottom: \"Convolution3\"\n",
      "  top: \"Crop3\"\n",
      "  crop_param {\n",
      "    axis: 2\n",
      "    offset: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Deconvolution4\"\n",
      "  type: \"Deconvolution\"\n",
      "  bottom: \"Crop3\"\n",
      "  top: \"Deconvolution4\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    bias_term: false\n",
      "    pad: 0\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU11\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Deconvolution4\"\n",
      "  top: \"Deconvolution4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Crop4\"\n",
      "  type: \"Crop\"\n",
      "  bottom: \"Deconvolution4\"\n",
      "  bottom: \"Convolution2\"\n",
      "  top: \"Crop4\"\n",
      "  crop_param {\n",
      "    axis: 2\n",
      "    offset: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Deconvolution5\"\n",
      "  type: \"Deconvolution\"\n",
      "  bottom: \"Crop4\"\n",
      "  top: \"Deconvolution5\"\n",
      "  convolution_param {\n",
      "    num_output: 128\n",
      "    bias_term: false\n",
      "    pad: 0\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU12\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Deconvolution5\"\n",
      "  top: \"Deconvolution5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Crop5\"\n",
      "  type: \"Crop\"\n",
      "  bottom: \"Deconvolution5\"\n",
      "  bottom: \"Convolution1\"\n",
      "  top: \"Crop5\"\n",
      "  crop_param {\n",
      "    axis: 2\n",
      "    offset: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Deconvolution6\"\n",
      "  type: \"Deconvolution\"\n",
      "  bottom: \"Crop5\"\n",
      "  top: \"Deconvolution6\"\n",
      "  convolution_param {\n",
      "    num_output: 16\n",
      "    bias_term: false\n",
      "    pad: 0\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU13\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Deconvolution6\"\n",
      "  top: \"Deconvolution6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Crop6\"\n",
      "  type: \"Crop\"\n",
      "  bottom: \"Deconvolution6\"\n",
      "  bottom: \"DummyData1\"\n",
      "  top: \"Crop6\"\n",
      "  crop_param {\n",
      "    axis: 2\n",
      "    offset: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"EuclideanLoss2\"\n",
      "  type: \"EuclideanLoss\"\n",
      "  bottom: \"Crop6\"\n",
      "  bottom: \"DummyData1\"\n",
      "  top: \"EuclideanLoss2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Eltwise1\"\n",
      "  type: \"Eltwise\"\n",
      "  bottom: \"EuclideanLoss1\"\n",
      "  bottom: \"EuclideanLoss2\"\n",
      "  top: \"Eltwise1\"\n",
      "  eltwise_param {\n",
      "    operation: SUM\n",
      "    engine: CAFFE\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print newstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
