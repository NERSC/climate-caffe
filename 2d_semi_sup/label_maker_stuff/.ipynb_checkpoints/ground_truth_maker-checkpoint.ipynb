{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from label_loader.ipynb\n",
      "importing Jupyter notebook from util.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import numpy as np\n",
    "import time\n",
    "from label_loader import  make_labels_for_dataset\n",
    "import h5py\n",
    "import os\n",
    "from os.path import join\n",
    "from util import get_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gr_truth_configs(kwargs):\n",
    "    scale_factor = float(kwargs[\"scale_factor\"])\n",
    "    xdim, ydim = kwargs[\"xdim\"], kwargs[\"ydim\"]\n",
    "    num_classes = kwargs[\"num_classes\"]\n",
    "    #make sure xy coords divide cleanly with scale_factor\n",
    "    assert xdim % scale_factor == 0 and ydim % scale_factor == 0, \"scale factor %i must divide the xy (%i, %i) coords cleanly \" %(scale_factor,xdim, ydim)\n",
    "    \n",
    "    xlen, ylen = xdim / int(scale_factor), ydim / int(scale_factor)\n",
    "    \n",
    "    #x,y,w,h,conf1,conf2 plus num_classes for one hot encoding\n",
    "    if kwargs[\"caffe_format\"]:\n",
    "        last_dim = 6  #(xywh obj cls)\n",
    "    else:\n",
    "        last_dim = 6 + num_classes\n",
    "    return scale_factor, xlen, ylen, last_dim, num_classes \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xy_inds(x,y, scale_factor):\n",
    "        # get the indices to the lower left corner of the grid\n",
    "        \n",
    "        #scale x and y down\n",
    "        xs, ys = x / scale_factor, y / scale_factor\n",
    "        eps = 10*np.finfo(float).eps\n",
    "        #take the floor of x and y -> which is rounding to nearest bottom left corner\n",
    "        x_ind, y_ind = [np.floor(k - 10*eps ).astype('int') for k in [xs,ys]]\n",
    "        return x_ind, y_ind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xy_offsets(x,y, x_ind, y_ind, scale_factor):\n",
    "    #scale x and y down\n",
    "    xs, ys = x / scale_factor, y / scale_factor\n",
    "    \n",
    "    #get the offsets by subtracting the scaled lower left corner coords from the scaled real coords\n",
    "    xoff, yoff = xs - x_ind, ys - y_ind\n",
    "    \n",
    "    return xoff, yoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parametrized_wh(w,h,scale_factor):\n",
    "    ws , hs = w / scale_factor, h/ scale_factor\n",
    "    wp, hp = np.log2(ws), np.log2(hs)\n",
    "    return wp, hp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_class_to_one_hot(class_num, num_classes):\n",
    "    vec = num_classes * [0]\n",
    "    vec[class_num - 1] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_box_vector(coords, scale_factor, num_classes, caffe_format):\n",
    "    x,y,w,h,cls = coords\n",
    "    xind, yind = get_xy_inds(x,y,scale_factor)\n",
    "    xoff, yoff = get_xy_offsets(x, y, xind, yind, scale_factor)\n",
    "    wp, hp = get_parametrized_wh(w, h, scale_factor)\n",
    "    if caffe_format:\n",
    "        cls_vec = [cls] #classes are 1-4 (no zero on purpose, so that can be filtered out)\n",
    "        objectness_vec = [1]\n",
    "    else:\n",
    "        cls_vec = convert_class_to_one_hot(cls, num_classes=num_classes)\n",
    "        objectness_vec = [1, 0]\n",
    "    box_loc = [xoff, yoff, wp, hp]\n",
    "    box_vec = np.asarray(box_loc + objectness_vec + cls_vec)\n",
    "    return box_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_grid(bbox, grid,kwargs):\n",
    "    xdim, ydim, scale_factor,num_classes, caffe_format = kwargs[\"xdim\"], kwargs[\"ydim\"],kwargs[\"scale_factor\"], kwargs[\"num_classes\"],kwargs[\"caffe_format\"]\n",
    "    scale_factor = float(scale_factor)\n",
    "    cls = int(bbox[4])\n",
    "    x,y = bbox[0] / scale_factor, bbox[1] / scale_factor\n",
    "\n",
    "    xo,yo = x - np.floor(x), y - np.floor(y)\n",
    "    w,h = np.log2(bbox[2] / scale_factor), np.log2(bbox[3] / scale_factor)\n",
    "\n",
    "\n",
    "\n",
    "    if caffe_format:\n",
    "        depth = 6\n",
    "        caffe_box = grid[:depth,int(x),int(y)]\n",
    "        l_box = caffe_box\n",
    "        lbl = [cls]\n",
    "        obj = [1.]\n",
    "    else:\n",
    "        depth = 6 + num_classes\n",
    "        oth_box = grid[int(x),int(y),:depth]\n",
    "        l_box = oth_box\n",
    "        obj = [1., 0.]\n",
    "        \n",
    "\n",
    "        lbl = num_classes*[0]\n",
    "        lbl[cls-1] = 1\n",
    "    \n",
    "    real_box = [xo,yo,w,h] + obj\n",
    "    real_box.extend(lbl)\n",
    "    \n",
    "    print l_box\n",
    "\n",
    "    print real_box\n",
    "    assert np.allclose(l_box, real_box), \"Tests Failed\"\n",
    "#     if np.allclose(l_box, real_box) == True:\n",
    "#         print \"Yay! Passed Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_default_no_object_1hot(gr_truth):\n",
    "    #make the 5th number 1, so the objectness by defualt is 0,1 -> denoting no object\n",
    "    gr_truth[:,:,:,5] = 1.\n",
    "    return gr_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_yolo_gr_truth(bbox_list, kwargs, year):\n",
    "        caffe_format = kwargs[\"caffe_format\"]\n",
    "        scale_factor, xlen, ylen, last_dim, num_classes = get_gr_truth_configs(kwargs)\n",
    "\n",
    "        num_time_steps = len(bbox_list)\n",
    "        \n",
    "        gr_truth = np.zeros(( num_time_steps, xlen, ylen, last_dim ))\n",
    "\n",
    "        # if the file is specified as unlabelled then we skip this\n",
    "        # and return gr_truth as is -> all zeros\n",
    "        if ts.year not in kwargs[\"unlabelled_data\"]:\n",
    "            if not caffe_format:\n",
    "                gr_truth = make_default_no_object_1hot(gr_truth)\n",
    "            # for caffe we have the channels as the following x,y,w,h,obj,cls\n",
    "            # obj is 1 or 0 and cls is 1-4 if an obj is there and 0 if not\n",
    "            #For noncaffe we have x,y,w,h,obj,no-obj, cls1,cls2,cls3,cls4\n",
    "            #cls1-cls4 is one hot encoded vector\n",
    "            for time_step in range(num_time_steps):\n",
    "                for coords in bbox_list[time_step]:\n",
    "                    x,y,w,h,cls = coords\n",
    "\n",
    "                    xind, yind = get_xy_inds(x,y,scale_factor)\n",
    "                    box_vec = get_box_vector(coords, scale_factor, num_classes, caffe_format)\n",
    "                    gr_truth[time_step,xind,yind,:] = box_vec\n",
    "\n",
    "        if caffe_format:\n",
    "            gr_truth = np.transpose(gr_truth, axes=(0,3,1,2))\n",
    "        return gr_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_yolo_masks_for_dataset( camfile_path, kwargs, labels_csv_file):\n",
    "        ts = get_timestamp(camfile_path)\n",
    "        box_list = make_labels_for_dataset(camfile_path, labels_csv_file)\n",
    "        yolo_mask = create_yolo_gr_truth(box_list, kwargs, ts.year)\n",
    "        return yolo_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_mask(camfile_name, mask, save_loc):\n",
    "    h5f_name = camfile_name.split(\".nc\")[0] + \".h5\"\n",
    "    hf = h5py.File(join(save_loc, h5f_name))\n",
    "    hfd = hf.create_dataset(name=\"label\", data=mask)\n",
    "    hf.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_label_tensors_to_hdf5(kwargs):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    labels_csv_file = join(kwargs[\"metadata_dir\"], \"labels.csv\")\n",
    "    \n",
    "\n",
    "\n",
    "    for camfile_name in os.listdir(kwargs[\"data_dir\"]):\n",
    "\n",
    "        camfile_path = join(kwargs[\"data_dir\"], camfile_name)\n",
    "        if \"2005\" in camfile_name:\n",
    "            ym = make_yolo_masks_for_dataset(camfile_path,\n",
    "                                     kwargs,\n",
    "                                    labels_csv_file)\n",
    "\n",
    "            print ym\n",
    "            #test(camfile_path, ym, kwargs)\n",
    "            save_mask(camfile_name, ym, save_loc=\"\")\n",
    "            assert False\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(camfile_path, mask, kwargs):\n",
    "    labels_csv_file = join(kwargs[\"metadata_dir\"], \"labels.csv\")\n",
    "    box_list = make_labels_for_dataset(camfile_path, labels_csv_file)\n",
    "    box = box_list[0][0]\n",
    "    test_grid(box, mask[0], kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_hdf5_file(h5f_path, camfile_path, kwargs):\n",
    "\n",
    "\n",
    "    labels_csv_file = join(kwargs[\"metadata_dir\"], \"labels.csv\")\n",
    "    ym = h5py.File(h5f_path)[\"label\"]\n",
    "    test(camfile_path, ym, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'fname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-44f25b436962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dest_dir\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/global/cscratch1/sd/racah/TCHero/unlabelled_labels\"\u001b[0m \u001b[0;31m#kwargs[\"metadata_dir\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msave_label_tensors_to_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a397f3070092>\u001b[0m in \u001b[0;36msave_label_tensors_to_hdf5\u001b[0;34m(kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m             ym = make_yolo_masks_for_dataset(camfile_path,\n\u001b[1;32m     15\u001b[0m                                      \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                     labels_csv_file)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-af322172514d>\u001b[0m in \u001b[0;36mmake_yolo_masks_for_dataset\u001b[0;34m(camfile_path, kwargs, labels_csv_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_yolo_masks_for_dataset\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcamfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_csv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mbox_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_labels_for_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_csv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0myolo_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_yolo_gr_truth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0myolo_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-50eaa02ac914>\u001b[0m in \u001b[0;36mcreate_yolo_gr_truth\u001b[0;34m(bbox_list, kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mcaffe_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"caffe_format\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gr_truth_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnum_time_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'fname' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    kwargs = {  \"metadata_dir\": \"/global/cscratch1/sd/racah/TCHero/labels\",\n",
    "                \"data_dir\": \"/global/cscratch1/sd/racah/TCHero/data\",\n",
    "                \"scale_factor\": 64, \n",
    "                \"xdim\":768,\n",
    "                \"ydim\":1152,\n",
    "                \"time_steps_per_file\": 8,\n",
    "                \"num_classes\": 4, \"caffe_format\": True, \"unlabelled_years\":[2005] }\n",
    "\n",
    "    kwargs[\"dest_dir\"] = \"/global/cscratch1/sd/racah/TCHero/unlabelled_labels\" #kwargs[\"metadata_dir\"]\n",
    "    save_label_tensors_to_hdf5(kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         3.,  0.,  0.,  0.,  3.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a=h5py.File(\"/global/cscratch1/sd/racah/TCHero/labels/cam5_1_amip_run2.cam2.h2.1983-07-02-00000.h5\")\n",
    "\n",
    "# a[\"label\"][2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
