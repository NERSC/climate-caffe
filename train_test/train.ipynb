{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import caffe\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from generate_prototxt_files import *\n",
    "from os.path import join, basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cl_args(cl_args):\n",
    "\n",
    "\n",
    "\n",
    "    if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "        sys.argv=sys.argv[:1]\n",
    "\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    for k,v in cl_args.iteritems():\n",
    "        parser.add_argument('--' + k, type=type(v), default=v, help=k)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    cl_args.update(args.__dict__)\n",
    "    return cl_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_plot(cl_args):\n",
    "    suffix = \"learning_curve_lr_%8.6f_%s.jpg\"%(cl_args[\"lr\"],basename(cl_args[\"solver_path\"]))\n",
    "    plt.figure(1)\n",
    "    plt.plot([losses[str(epoch) + \"_mean\"][\"final_loss\"] for epoch in range(ep + 1)])\n",
    "    #plt.show()\n",
    "    plt.savefig(join(cl_args[\"save_dir\"],\"tr_\" + suffix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_epoch_losses(losses, loss_keys,ep):\n",
    "    losses[str(ep) + \"_mean\"] = {k:np.mean(losses[ep][k]) for k in loss_keys}\n",
    "    for k in loss_keys:\n",
    "        loss = losses[str(ep) + \"_mean\"][k]\n",
    "        sys.stderr.write(\"\\n Epoch %i: Final %s Loss = %6.3f\\n\" % (ep, k, loss))\n",
    "        sys.stderr.flush()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_iteration_losses(losses, solver,loss_keys,it):\n",
    "    for k in loss_keys:\n",
    "        loss = np.float32(solver.net.blobs[k].data)\n",
    "        losses[ep][k].append(loss)\n",
    "        sys.stderr.write(\"\\n Loss at iteration %i for %s is %8.4f \" % (it,k,loss))\n",
    "        sys.stderr.flush()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def do_train(solver, cl_args):\n",
    "    num_tr = 32 #get_num_examples(join(cl_args[\"proto_basepath\"], cl_args[\"train_proto_name\"]))\n",
    "    tr_its_per_epoch = int(float(num_tr) / cl_args[\"tr_batch_size\"])\n",
    "    #val_its_per_epoch = int(float(num_val) / val_batch_size)\n",
    "    num_epochs = cl_args[\"num_epochs\"]\n",
    "\n",
    "    loss_keys = [\"L_cls\",\"L_obj\",\"L_xy\",\"L_wh\",\"L_rec\",\"final_loss\"]\n",
    "    losses = {}\n",
    "    \n",
    "    for ep in range(num_epochs):\n",
    "        losses[ep] = {k:[] for k in loss_keys}\n",
    "        losses[str(ep) + \"_mean\"] = {k:0 for k in loss_keys}\n",
    "        for it in range(tr_its_per_epoch):\n",
    "            solver.step(1)\n",
    "            \n",
    "            losses = write_iteration_losses(losses, solver,loss_keys,it)\n",
    "            \n",
    "        losses = write_epoch_losses(losses, loss_keys,ep)\n",
    "\n",
    "        save_plot(cl_args)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    cl_args = {\"solver_path\": \"/project/projectdirs/dasrepo/gordon_bell/deep_learning/networks/climate/2d_semi_sup/really_small_test/node_49_solver_vanilla.prototxt\" }\n",
    "    cl_args = get_cl_args(cl_args)\n",
    "    solver = caffe.SGDSolver(cl_args[\"solver_path\"])\n",
    "    solver.step(1)\n",
    "    #do_train(solver, cl_args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
