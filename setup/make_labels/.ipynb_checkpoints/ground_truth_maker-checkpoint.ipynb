{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from label_loader.ipynb\n",
      "importing Jupyter notebook from util.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import numpy as np\n",
    "import time\n",
    "from label_loader import  make_labels_for_dataset\n",
    "import h5py\n",
    "import os\n",
    "from os.path import join\n",
    "from util import get_timestamp\n",
    "import netCDF4 as nc\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_gr_truth_configs(kwargs):\n",
    "    scale_factor = float(kwargs[\"scale_factor\"])\n",
    "    xdim, ydim = kwargs[\"xdim\"], kwargs[\"ydim\"]\n",
    "    num_classes = kwargs[\"num_classes\"]\n",
    "    #make sure xy coords divide cleanly with scale_factor\n",
    "    assert xdim % scale_factor == 0 and ydim % scale_factor == 0, \"scale factor %i must divide the xy (%i, %i) coords cleanly \" %(scale_factor,xdim, ydim)\n",
    "    \n",
    "    xlen, ylen = xdim / int(scale_factor), ydim / int(scale_factor)\n",
    "    \n",
    "    #x,y,w,h,conf1,conf2 plus num_classes for one hot encoding\n",
    "    if kwargs[\"caffe_format\"]:\n",
    "        last_dim = 6  #(xywh obj cls)\n",
    "    else:\n",
    "        last_dim = 6 + num_classes\n",
    "    return scale_factor, xlen, ylen, last_dim, num_classes \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_xy_inds(x,y, scale_factor):\n",
    "        # get the indices to the lower left corner of the grid\n",
    "        \n",
    "        #scale x and y down\n",
    "        xs, ys = x / scale_factor, y / scale_factor\n",
    "        eps = 10*np.finfo(float).eps\n",
    "        #take the floor of x and y -> which is rounding to nearest bottom left corner\n",
    "        x_ind, y_ind = [np.floor(k - 10*eps ).astype('int') for k in [xs,ys]]\n",
    "        return x_ind, y_ind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_xy_offsets(x,y, x_ind, y_ind, scale_factor):\n",
    "    #scale x and y down\n",
    "    xs, ys = x / scale_factor, y / scale_factor\n",
    "    \n",
    "    #get the offsets by subtracting the scaled lower left corner coords from the scaled real coords\n",
    "    xoff, yoff = xs - x_ind, ys - y_ind\n",
    "    \n",
    "    return xoff, yoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_parametrized_wh(w,h,scale_factor):\n",
    "    ws , hs = w / scale_factor, h/ scale_factor\n",
    "    wp, hp = np.log2(ws), np.log2(hs)\n",
    "    return wp, hp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_class_to_one_hot(class_num, num_classes):\n",
    "    vec = num_classes * [0]\n",
    "    vec[class_num - 1] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_box_vector(coords, scale_factor, num_classes, caffe_format):\n",
    "    x,y,w,h,cls = coords\n",
    "    xind, yind = get_xy_inds(x,y,scale_factor)\n",
    "    xoff, yoff = get_xy_offsets(x, y, xind, yind, scale_factor)\n",
    "    wp, hp = get_parametrized_wh(w, h, scale_factor)\n",
    "    if caffe_format:\n",
    "        cls_vec = [cls] #classes are 1-4 (no zero on purpose, so that can be filtered out)\n",
    "        objectness_vec = [1]\n",
    "    else:\n",
    "        cls_vec = convert_class_to_one_hot(cls, num_classes=num_classes)\n",
    "        objectness_vec = [1, 0]\n",
    "    box_loc = [xoff, yoff, wp, hp]\n",
    "    box_vec = np.asarray(box_loc + objectness_vec + cls_vec)\n",
    "    return box_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_grid(bbox, grid,kwargs):\n",
    "    xdim, ydim, scale_factor,num_classes, caffe_format = kwargs[\"xdim\"], kwargs[\"ydim\"],kwargs[\"scale_factor\"], kwargs[\"num_classes\"],kwargs[\"caffe_format\"]\n",
    "    scale_factor = float(scale_factor)\n",
    "    cls = int(bbox[4])\n",
    "    x,y = bbox[0] / scale_factor, bbox[1] / scale_factor\n",
    "\n",
    "    xo,yo = x - np.floor(x), y - np.floor(y)\n",
    "    w,h = np.log2(bbox[2] / scale_factor), np.log2(bbox[3] / scale_factor)\n",
    "\n",
    "\n",
    "\n",
    "    if caffe_format:\n",
    "        depth = 6\n",
    "        caffe_box = grid[:depth,int(x),int(y)]\n",
    "        l_box = caffe_box\n",
    "        lbl = [cls]\n",
    "        obj = [1.]\n",
    "    else:\n",
    "        depth = 6 + num_classes\n",
    "        oth_box = grid[int(x),int(y),:depth]\n",
    "        l_box = oth_box\n",
    "        obj = [1., 0.]\n",
    "        \n",
    "\n",
    "        lbl = num_classes*[0]\n",
    "        lbl[cls-1] = 1\n",
    "    \n",
    "    real_box = [xo,yo,w,h] + obj\n",
    "    real_box.extend(lbl)\n",
    "    \n",
    "    print l_box\n",
    "\n",
    "    print real_box\n",
    "    assert np.allclose(l_box, real_box), \"Tests Failed\"\n",
    "#     if np.allclose(l_box, real_box) == True:\n",
    "#         print \"Yay! Passed Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_default_no_object_1hot(gr_truth):\n",
    "    #make the 5th number 1, so the objectness by defualt is 0,1 -> denoting no object\n",
    "    gr_truth[:,:,:,5] = 1.\n",
    "    return gr_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_yolo_gr_truth(bbox_list, kwargs, year):\n",
    "        caffe_format = kwargs[\"caffe_format\"]\n",
    "        scale_factor, xlen, ylen, last_dim, num_classes = get_gr_truth_configs(kwargs)\n",
    "\n",
    "        num_time_steps = len(bbox_list)\n",
    "        \n",
    "        gr_truth = np.zeros(( num_time_steps, xlen, ylen, last_dim ))\n",
    "\n",
    "        # if the file is specified as unlabelled then we skip this\n",
    "        # and return gr_truth as is -> all zeros\n",
    "        if year not in kwargs[\"unlabelled_years\"]:\n",
    "            if not caffe_format:\n",
    "                gr_truth = make_default_no_object_1hot(gr_truth)\n",
    "            # for caffe we have the channels as the following x,y,w,h,obj,cls\n",
    "            # obj is 1 or 0 and cls is 1-4 if an obj is there and 0 if not\n",
    "            #For noncaffe we have x,y,w,h,obj,no-obj, cls1,cls2,cls3,cls4\n",
    "            #cls1-cls4 is one hot encoded vector\n",
    "            for time_step in range(num_time_steps):\n",
    "                for coords in bbox_list[time_step]:\n",
    "                    x,y,w,h,cls = coords\n",
    "\n",
    "                    xind, yind = get_xy_inds(x,y,scale_factor)\n",
    "                    box_vec = get_box_vector(coords, scale_factor, num_classes, caffe_format)\n",
    "                    gr_truth[time_step,xind,yind,:] = box_vec\n",
    "\n",
    "        if caffe_format:\n",
    "            gr_truth = np.transpose(gr_truth, axes=(0,3,1,2))\n",
    "        return gr_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_yolo_masks_for_dataset( camfile_path, kwargs, labels_csv_file):\n",
    "        ts = get_timestamp(camfile_path)\n",
    "        box_list = make_labels_for_dataset(camfile_path, labels_csv_file)\n",
    "        yolo_mask = create_yolo_gr_truth(box_list, kwargs, ts.year)\n",
    "        return yolo_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_mask(camfile_name, mask, save_loc, fmt=\"netcdf\"):\n",
    "\n",
    "    def save_mask_netcdf():\n",
    "        netcdf_name = camfile_name.split(\".nc\")[0] + \"_label.nc\"\n",
    "        rootgrp = nc.Dataset(join(save_loc, netcdf_name), \"w\")\n",
    "\n",
    "        time = rootgrp.createDimension(\"time\", mask.shape[0])\n",
    "        xdim = rootgrp.createDimension(\"x\", mask.shape[2])\n",
    "        ydim = rootgrp.createDimension(\"y\", mask.shape[3])\n",
    "\n",
    "        x_coord = rootgrp.createVariable(\"x_coord\",\"f4\",(\"time\",\"x\",\"y\"))\n",
    "        y_coord = rootgrp.createVariable(\"y_coord\",\"f4\",(\"time\",\"x\",\"y\"))\n",
    "        w_coord = rootgrp.createVariable(\"w_coord\",\"f4\",(\"time\",\"x\",\"y\"))\n",
    "        h_coord = rootgrp.createVariable(\"h_coord\",\"f4\",(\"time\",\"x\",\"y\"))\n",
    "        obj = rootgrp.createVariable(\"obj\",\"f4\",(\"time\",\"x\",\"y\"))\n",
    "        cls = rootgrp.createVariable(\"cls\",\"f4\",(\"time\",\"x\",\"y\"))\n",
    "\n",
    "        vars_ = [x_coord, y_coord, w_coord, h_coord, obj, cls]\n",
    "        for i,var in enumerate(vars_):\n",
    "            # for every example for the correct variable, for al x and y\n",
    "            var[:] = mask[:,i,:,:]\n",
    "\n",
    "    \n",
    "    \n",
    "        rootgrp.close()\n",
    "    \n",
    "    def save_mask_hdf5():\n",
    "        h5f_name = camfile_name.split(\".nc\")[0] + \".h5\"\n",
    "        hf = h5py.File(join(save_loc, h5f_name))\n",
    "        hfd = hf.create_dataset(name=\"label\", data=mask)\n",
    "        hf.close()\n",
    "    if fmt == \"netcdf\":\n",
    "        save_mask_netcdf()\n",
    "    else:\n",
    "        save_mask_hdf5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_label_tensors(kwargs):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    labels_csv_file = join(kwargs[\"metadata_dir\"], \"labels.csv\")\n",
    "    \n",
    "\n",
    "\n",
    "    for camfile_name in [\"cam5_1_amip_run2.cam2.h2.1981-01-01-00000.nc\"]:#os.listdir(kwargs[\"data_dir\"]):\n",
    "        print camfile_name\n",
    "        camfile_path = join(kwargs[\"data_dir\"], camfile_name)\n",
    "        \n",
    "        if \"amip\" in camfile_name:\n",
    "            ym = make_yolo_masks_for_dataset(camfile_path,\n",
    "                                     kwargs,\n",
    "                                    labels_csv_file)\n",
    "            if kwargs[\"with_unlabelled_frames\"]:\n",
    "                ym_z = np.zeros((kwargs[\"time_steps_per_file\"], ym.shape[1], ym.shape[2], ym.shape[3]))\n",
    "                ym_z[0::2] = ym\n",
    "                ym = ym_z\n",
    "        else:\n",
    "            ym = np.zeros((kwargs[\"time_steps_per_file\"], \n",
    "                           6, \n",
    "                           kwargs[\"xdim\"] / kwargs[\"scale_factor\"], \n",
    "                           kwargs[\"ydim\"] / kwargs[\"scale_factor\"]\n",
    "                          ))\n",
    "\n",
    "\n",
    "        #test(camfile_path, ym, kwargs)\n",
    "        save_mask(camfile_name, ym, save_loc=kwargs[\"dest_dir\"], fmt=kwargs[\"file_format\"])\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(camfile_path, mask, kwargs):\n",
    "    labels_csv_file = join(kwargs[\"metadata_dir\"], \"labels.csv\")\n",
    "    box_list = make_labels_for_dataset(camfile_path, labels_csv_file)\n",
    "    box = box_list[0][0]\n",
    "    test_grid(box, mask[0], kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_hdf5_file(h5f_path, camfile_path, kwargs):\n",
    "\n",
    "\n",
    "    labels_csv_file = join(kwargs[\"metadata_dir\"], \"labels.csv\")\n",
    "    ym = h5py.File(h5f_path)[\"label\"]\n",
    "    test(camfile_path, ym, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam5_1_amip_run2.cam2.h2.1981-01-01-00000.nc\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--data_dir', type=str)\n",
    "#     parser.add_argument('--dest_dir', type=str)\n",
    "#     if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "#         sys.argv=sys.argv[:1]\n",
    "#     args = parser.parse_args().__dict__\n",
    "    \n",
    "    kwargs = {  \"metadata_dir\": \"/global/cscratch1/sd/racah/climate_data/climo/csv_labels\",\n",
    "                \"data_dir\": \"/global/cscratch1/sd/racah/climate_data/climo/images\",\n",
    "                \"scale_factor\": 32, \n",
    "                \"xdim\":768,\n",
    "                \"ydim\":1152,\n",
    "                \"time_steps_per_file\": 8,\n",
    "                \"file_format\": \"netcdf\",\n",
    "                \"with_unlabelled_frames\": True,\n",
    "                \"dest_dir\": \"/global/cscratch1/sd/racah/climate_data/climo/labels\",\n",
    "                \"num_classes\": 4, \"caffe_format\": True, \"unlabelled_years\": [] }\n",
    "    #kwargs.update(args)\n",
    "    save_label_tensors(kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7a5b11ed10>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD7CAYAAAClvBX1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b7a5ac9ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "d=nc.Dataset(\n",
    "    \"\"\"/project/projectdirs/dasrepo/gordon_bell/deep_learning/data/climate/CAM5_0.25/climo/labels/cam5_1_amip_run2.cam2.h2.1995-08-25-10800_label.nc\"\"\")\n",
    "\n",
    "plt.imshow(d[\"obj\"][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
