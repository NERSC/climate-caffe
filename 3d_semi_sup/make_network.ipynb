{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L, params as P, to_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from caffe.proto import caffe_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data, label = L.Data(source=\"./train.txt\", backend=P.Data.LMDB, batch_size=3, ntop=2,\n",
    "#         transform_param=dict(crop_size=227, mean_value=[104, 117, 123], mirror=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(bottom, ks, nout, stride=1, pad=0, group=1):\n",
    "    conv = L.Convolution(bottom, kernel_size=ks, stride=stride,\n",
    "                                num_output=nout, pad=pad, group=group)\n",
    "    return L.ReLU(conv, in_place=True)\n",
    "\n",
    "def fc_relu(bottom, nout):\n",
    "    fc = L.InnerProduct(bottom, num_output=nout)\n",
    "    return fc, L.ReLU(fc, in_place=True)\n",
    "\n",
    "def max_pool(bottom, ks=2, stride=2):\n",
    "    return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deconv_relu(bottom, ks, nout, stride=1, pad=0, group=1):\n",
    "    convolution_param = dict(num_output=nout, kernel_size=ks, stride=stride,pad=pad, group=group,\n",
    "            bias_term=False)\n",
    "    deconv = L.Deconvolution(bottom,convolution_param=convolution_param)\n",
    "    return L.ReLU(deconv, in_place=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "data =L.NetCDFData(source=\"train.txt\", variable_data=['PRECT',\n",
    "                                                     'PS',\n",
    "                                                     'PSL',\n",
    "                                                     'QREFHT',\n",
    "                                                     'T200',\n",
    "                                                     'T500',\n",
    "                                                     'TMQ',\n",
    "                                                     'TREFHT',\n",
    "                                                     'TS',\n",
    "                                                     'U850',\n",
    "                                                     'UBOT',\n",
    "                                                     'V850',\n",
    "                                                     'VBOT',\n",
    "                                                     'Z1000',\n",
    "                                                     'Z200', 'ZBOT'],\n",
    "                   variable_label = [\"teca_mask\"], first_dim_is_batched=True,\n",
    "                 batch_size=batch_size)\n",
    "\n",
    "\n",
    "data = L.DummyData(shape={'dim':[batch_size,16,768,1152]})\n",
    "label = L.DummyData(shape={'dim':[batch_size,6,12,18]})\n",
    "\n",
    "\n",
    "nfilters = 32\n",
    "\n",
    "conv = data\n",
    "\n",
    "num_layers = 6\n",
    "\n",
    "for i in range(num_layers):\n",
    "    nfilters *= 2\n",
    "    conv = conv_relu(conv, ks=5, nout=nfilters, pad=2, stride=1)\n",
    "    conv = max_pool(conv)\n",
    "    \n",
    "conv = L.Convolution(conv,kernel_size=1,num_output=6, stride=1 )\n",
    "\n",
    "loss = L.EuclideanLoss(conv, label)\n",
    "\n",
    "prototxt_str = str(to_proto(loss))\n",
    "\n",
    "# #man oh man this is hacky\n",
    "# #add in second top for netcdf data layer\n",
    "# str_of_int = 'top: \"NetCDFData1\"\\n '\n",
    "\n",
    "# insert_ind = prototxt_str.index(str_of_int) + len(str_of_int)\n",
    "# insert_str = ' top: \"NetCDFData2\"\\n ' \n",
    "# prototxt_str = prototxt_str[:insert_ind] + insert_str + prototxt_str[insert_ind:]\n",
    "\n",
    "# prototxt_str = prototxt_str.replace(\"NetCDFData1\", \"data\")\n",
    "# prototxt_str =prototxt_str.replace(\"NetCDFData2\", \"label\")\n",
    "\n",
    "# #print prototxt_str\n",
    "with open('train.prototxt', 'w') as f:\n",
    "        f.write(prototxt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\n",
      "  name: \"DummyData1\"\n",
      "  type: \"DummyData\"\n",
      "  top: \"DummyData1\"\n",
      "  dummy_data_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 16\n",
      "      dim: 768\n",
      "      dim: 1152\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"DummyData1\"\n",
      "  top: \"Convolution1\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution1\"\n",
      "  top: \"Convolution1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Pooling1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"Convolution1\"\n",
      "  top: \"Pooling1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Pooling1\"\n",
      "  top: \"Convolution2\"\n",
      "  convolution_param {\n",
      "    num_output: 128\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution2\"\n",
      "  top: \"Convolution2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Pooling2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"Convolution2\"\n",
      "  top: \"Pooling2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Pooling2\"\n",
      "  top: \"Convolution3\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution3\"\n",
      "  top: \"Convolution3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Pooling3\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"Convolution3\"\n",
      "  top: \"Pooling3\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Pooling3\"\n",
      "  top: \"Convolution4\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution4\"\n",
      "  top: \"Convolution4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Pooling4\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"Convolution4\"\n",
      "  top: \"Pooling4\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Pooling4\"\n",
      "  top: \"Convolution5\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution5\"\n",
      "  top: \"Convolution5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Pooling5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"Convolution5\"\n",
      "  top: \"Pooling5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution6\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Pooling5\"\n",
      "  top: \"Convolution6\"\n",
      "  convolution_param {\n",
      "    num_output: 2048\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 1\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ReLU6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"Convolution6\"\n",
      "  top: \"Convolution6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"Pooling6\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"Convolution6\"\n",
      "  top: \"Pooling6\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"Convolution7\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"Pooling6\"\n",
      "  top: \"Convolution7\"\n",
      "  convolution_param {\n",
      "    num_output: 6\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"DummyData2\"\n",
      "  type: \"DummyData\"\n",
      "  top: \"DummyData2\"\n",
      "  dummy_data_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 6\n",
      "      dim: 12\n",
      "      dim: 18\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"EuclideanLoss1\"\n",
      "  type: \"EuclideanLoss\"\n",
      "  bottom: \"Convolution7\"\n",
      "  bottom: \"DummyData2\"\n",
      "  top: \"EuclideanLoss1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print prototxt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768 / 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1152 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
